{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "     <img style=\"float: right; padding-right: 10px\" width=\"100\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>\n",
    "     </div>\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Instructor(s):** Aaron Masino <br>\n",
    "\n",
    "## Lab 7: Introduction to Neural Networks with PyTorch & PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F \n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import torchmetrics as TM\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "dir_dataroot = os.path.join(\"..\", \"data\")\n",
    "create_data_directory(dir_dataroot)\n",
    "\n",
    "dir_lightning = os.path.join(\"..\", \"lightning\")\n",
    "create_data_directory(dir_lightning)\n",
    "\n",
    "SEED = 123456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Goals\n",
    "\n",
    "This lab will introduce you to the creation, training, and evaluation of deep learning neural network models using the [PyTorch](https://pytorch.org/) and [PyTorch Lightning](https://lightning.ai/pytorch-lightning) libraries. PyTorch contains core capabilities related to the development of deep learning models. PyTorch Lightning provides functionally that abstracts much of the process of training and evaluating deep learning models created with PyTorch.\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "- Create PyTorch Tensor objects using numpy arrays and built-in PyTorch functions\n",
    "- Apply element-wise operations on PyTorch Tensors\n",
    "- Apply matrix operations on PyTorch Tensors\n",
    "- Explain the use of CPU and GPU processing on Tensors\n",
    "- Create PyTorch DataSet and DataLoader objects\n",
    "- Create PyTorch Lightning DataModule objects\n",
    "- Create PyTorch modules in the context of neural networks\n",
    "- Create deep learning models by composing PyTorch Modules\n",
    "- Apply the PyTorch LightningModule class to encapsulate deep learning model training and prediction functionality\n",
    "- Apply the PyTorch Lightning Trainer class to train a deep learning model \n",
    "- Apply the TorchMetrics library to collect deep learning model performance data\n",
    "- Evaluate deep learning model performance using visualization and classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Tensors\n",
    "The primary data structure used in the PyTorch is the [Tensor](https://pytorch.org/docs/stable/tensors.html). `Tensor` objects are analagous to numpy arrays. Indeed, they have many of the same attributes as shown in the code cell below. One attribute that distinguishes PyTorch Tensors from numpy arrays is the `device` attribute. This attribute tells us if the memory where our Tensor is held is on the CPU RAM or on a GPU. Typically, our Python code will be executed on our computer's CPU (central processing unit). However, much of deep learning involves matrix multiplications (in fact many such multiplications). It turns out that GPUs (graphical processing units) are orders of magnitude faster than CPUs for matrix multiplications. Hence, it will be advantagous to move our Tensors to the GPU during model training and inference. PyTorch will make this process very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 3 dimensional tensor\n",
    "x = [[[1, 2], [3, 4]], \n",
    "     [[5, 6], [7, 8]],\n",
    "     [[9, 10], [11, 12]]]\n",
    "t1 = torch.tensor(x)\n",
    "\n",
    "# tensor attributes\n",
    "print(\"t.size() = \", t1.size())\n",
    "print(\"t.shape = \", t1.shape)\n",
    "print(\"t.dim() = \", t1.dim())\n",
    "print(\"t.dtype = \", t1.dtype)\n",
    "print(\"t.device = \", t1.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From numpy and back again\n",
    "\n",
    "PyTorch Tensors can be created from numpy arrays. The `Tensor` method, `numpy` will create a numpy array from the `Tensor` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(4,3)\n",
    "t1 = torch.tensor(x)\n",
    "print(\"t.dtype = \", t1.dtype)\n",
    "print(\"t.shape = \", t1.shape)    \n",
    "\n",
    "y = t1.numpy()\n",
    "print(\"y.dtype = \", y.dtype)\n",
    "print(\"y.shape = \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direclty from PyTorch\n",
    "PyTorch includes methods for creating arbitrary dimension and size Tensors similar to numpy. These include `ones`, `zeros`, and several random sampling based methods, such as `rand` which samples values from a uniform distrubtion on $\\left[0,1\\right)$ and `randn` which samples from the normal distribution with zero mean and unit standard deviation. For more details, see [PyTorch random sampling](https://pytorch.org/docs/main/torch.html#random-sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(2,1)\n",
    "print(t1)\n",
    "\n",
    "t1 = torch.zeros(2,2)\n",
    "print(t1)\n",
    "\n",
    "# uniform random numbers from [0,1)\n",
    "t1 = torch.rand(3,2)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor indexing, slicing, and values\n",
    "\n",
    "Tensors are index in the same manner as numpy arrays. Portions of tensors can be selected with index slicing that works the same way as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw from a normal distribution with mean=0 and std=1\n",
    "t1 = torch.randn(3,2)\n",
    "print(t1)\n",
    "\n",
    "# print th 0,0 element\n",
    "print(t1[0,0])\n",
    "\n",
    "# print the first row\n",
    "print(t1[0])\n",
    "\n",
    "# print the first column\n",
    "print(t1[:,0])\n",
    "\n",
    "# print the last two columns of the last two rows\n",
    "print(t1[-2:,-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is usefuly to work with the values held in a Tensor using the core Python types (i.e., float, int, boolean) rather than the Tensor object. The Tensor `item` method enables access to a single value. Use of the `item` method requires that the Tensor (or slice of the Tensor) has only one element. Otherwise, the Tensor `tolist` method can be used to obtain the values from indices of a Tensor or the entire Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(2,2)\n",
    "\n",
    "# get the value of item at 0,0 \n",
    "print(t1[0,0].item())\n",
    "\n",
    "# get the value of item at 0,1  \n",
    "print(t1[0,1].item())\n",
    "\n",
    "# get the values of the first row\n",
    "print(t1[0].tolist())\n",
    "\n",
    "# get all of the values\n",
    "print(t1.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element wise operation\n",
    "Just as with numpy arrays, the standard Python arithmetic operators are overriden for PyTorch Tensors to allow for element wise operation. For example, the binary operator `+` applied to Tensor objects, $t_1$ and $t_2$, each with $k$ elements will result in a single Tensor whose $k^{th}$ element is $t_1^{\\{k\\}} + t_2^{\\{k\\}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(2,2)\n",
    "t2 = torch.Tensor([[1,2], [10,20]])\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "# elementwise addition\n",
    "t3 = t1 + t2\n",
    "print('t1 + t2 = \\n', t3)\n",
    "\n",
    "# elementwise subtraction\n",
    "t3 = t1 - t2\n",
    "print('t1 - t2 = \\n', t3)\n",
    "\n",
    "# elementwise multiplication\n",
    "t3 = t1 * t2\n",
    "print('t1 * t2 = \\n', t3)\n",
    "\n",
    "# elementwise division\n",
    "t3 = t1 / t2\n",
    "print('t1 / t2 = \\n', t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication & dot products\n",
    "Matrix multiplication and vector dot products are integral operations to the computation in NNets for both model training and inference. PyTorch provides methods for both operations that are computationally efficient and are supported on CPU and GPU.\n",
    "\n",
    "The `dot` function can be called directly from a Tensor object or from the `torch` module. The dot product is a symmetric function, so the order of the arguments is arbitary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(10)\n",
    "t2 = torch.randn(10)\n",
    "\n",
    "# dot product\n",
    "dp = torch.dot(t1, t2)\n",
    "print('dot product = ', dp.item())\n",
    "print(dp.shape)\n",
    "\n",
    "# or .dot product\n",
    "dp = t1.dot(t2)\n",
    "print('dot product = ', dp.item())\n",
    "print(dp.shape)\n",
    "\n",
    "# or change the order of the arguments\n",
    "dp = t2.dot(t1)\n",
    "print('dot product = ', dp.item())\n",
    "print(dp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few equivalent methods for matrix multiplication with PyTorch Tensors including the `mm` and `matmul` methods accessible from either a Tensor object or the `torch` module. Additionally, the overridden `@` operator also yields the result of multiplying two matrices. Be careful, matrix multiplication is an asymmetric operation (i.e., the order of the arguments can produce different results). Additionally to perform matrix multiplication, the first matrix must have the same number of _columns_ as the second matrix has _rows_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(2,3)\n",
    "t2 = torch.randn(3,4)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "# matrix multiplication - all of the following are equivalent\n",
    "t3 = torch.mm(t1,t2)\n",
    "t3 = t1.mm(t2)\n",
    "t3 = torch.matmul(t1,t2)\n",
    "t3 = t1 @ t2\n",
    "print(t3)\n",
    "\n",
    "# the following will raise an error\n",
    "try:\n",
    "    t3 = t2 @ t1\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Tensors\n",
    "Tensors can be combined using the `cat` (concatenate), `vstack` (vertical stack), and `hstack` (horizontal stack) methods. The `cat` method includes the `dim` method which indicates on which Tensor dimension the arguments should be combined. The `vstack` method is equivalent to calling `cat` with `dim=0` and the `hstack` method is equivalent to calling `cat` with `dim=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(10)\n",
    "t2 = torch.rand(2)\n",
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "\n",
    "# concatenate one dimensional tensors\n",
    "ts = torch.cat((t1,t2))\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(2,3)\n",
    "t2 = torch.rand(4,3)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "# concatenate with vertical stacking\n",
    "# these are equivalent\n",
    "ts = torch.cat((t1,t2), dim=0)\n",
    "ts = torch.vstack((t1,t2))\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(2,3)\n",
    "t2 = torch.rand(2,2)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "# concatenate with horizontal stacking\n",
    "# these are equivalent\n",
    "ts = torch.cat((t1,t2), dim=1)\n",
    "ts = torch.hstack((t1,t2))\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know your dtypes\n",
    "The Tensor `dtypes` indicates the object type of the values held in the Tensor. Most Tensor operations with arity greater than one (i.e., functions that operate on two or more inputs) require that the Tensor arguments have the same `dtypes`. This is because Tensor operations are _vectorized_ which doesn't easily allow for mixed types. The values of a Tensor can be cast to different types using the `torch.Tensor.to` method (see, [here](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to)) using the appropriate `dtype` argument (see the complete list [here](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype)). Alternatively, the Tensor class also has methods such as the `float` to directly cast Tensors to specified types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(t1.dtype)\n",
    "\n",
    "try:\n",
    "    tr = torch.rand_like(t1) #this won't work because t1 is int and rand_like will create a float tensor\n",
    "except Exception as e:\n",
    "    print('Exception:')\n",
    "    print(e)\n",
    "\n",
    "# cast t to float\n",
    "tr = torch.rand_like(t1.float())\n",
    "print(t1.float() @ tr.T)\n",
    "\n",
    "# equivalent to\n",
    "tr = torch.rand_like(t1.to(dtype=torch.float32))\n",
    "print(t1.float() @ tr.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know your devices\n",
    "As noted above, PyTorch seamlessly manages transfer of Tensors between CPU and GPU memory. It is important to be able to identify where a given Tensor is stored. Of course, not all computing environments will support GPU usage, so one must first check if there is a PyTorch supported device. The code cell below shows how to check if there is a NVIDIA GPU with CUDA support available. If you are using a Mac, you can instead check if there is MPS support (see [here](https://pytorch.org/docs/main/notes/mps.html)). More recently, PyTorch is also providing support for AMD GPUs with ROCM support (see [here](https://pytorch.org/blog/pytorch-for-amd-rocm-platform-now-available-as-python-package/)). For more information on PyTorch acceleration options, see [here](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device)\n",
    "\n",
    "To specifically check if a CUDA GPU is available, we can use the `torch.cuda.is_available` method. Once we have confired that GPU (or other device) support is available, we can check the location of a given Tensor `t` with the `t.device` attribute. We can move a the tensor to the CUDA GPU using the `t.to('cuda')` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(3,4)\n",
    "\n",
    "# which device is this on?\n",
    "print('t.device = ', t1.device)\n",
    "\n",
    "# check if cuda is available\n",
    "print('torch.cuda.is_available() = ', torch.cuda.is_available())\n",
    "\n",
    "# move to gpu\n",
    "t1 = t1.to('cuda')\n",
    "print('t.device = ', t1.device)\n",
    "\n",
    "t2 = torch.randn(4,2)\n",
    "\n",
    "try:\n",
    "    print(t1 @ t2)\n",
    "except Exception as e:\n",
    "    print('Exception:')\n",
    "    print(e)\n",
    "\n",
    "# move to gpu\n",
    "t2 = t2.to('cuda')\n",
    "print('t.device = ', t2.device) \n",
    "\n",
    "# or use the device agnostic way\n",
    "t1 = torch.randn(3,4)\n",
    "t2 = torch.randn(4,2)\n",
    "t1 = t1.to(t2.device)\n",
    "print('t.device = ', t1.device)\n",
    "print(t1 @ t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Data Handling with PyTorch Lightning \n",
    "\n",
    "DataSets, DataLoaders, and DataModules oh my\n",
    "\n",
    "When developing NNet models, especially deep-learning models, we are usualy working with something other than tabular data such as images or text files. In many cases, there will be thousands to millions of such files. It is typically not feasible to load all of the samples into computer memory at the same time. Additionally, as we will discuss in lecture, we don't typically update NNet models using all of the data at once (as is done in standard _Batch Gradient Descent_). Instead, the training data is divided into equal sized subsets, called __mini-batches__. For each _mini-batch_, the model predictions are generated and used to compute the loss function value. The loss function derivatives (computed via backpropagation) are then used to update model parameters. This process is known as _mini-batch gradient descent_. The process continues until all _mini-batches_ have been used, which is referred to as an __epoch__. Typically, NNets are trained form multiple `epochs`, meaning the entire training dataset is used multiple times to adjust the model learning paramaters.\n",
    "\n",
    "To enable this functionality in an efficient manner, we will use three data hanlding clsses. The first two, `DataSet` and `DataLoader` are part of the PyTorch library. The third, `DataModule` is from the PyTorch Lightning library.\n",
    "- DataSets are responsible for holding information about the dataset and methods to manipulate individual samples.\n",
    "- DataLoaders use the DataSets and other methods to load data for use in model training, evaluation, and inference. It is typical to have training, validation, and evaluation instances of DataLoaders for a given DataSet\n",
    "- DataModules encapsulate multiple DataLoaders and other methods for working with a DataSet for modle training and evaluation including batching data samples.\n",
    "\n",
    "We introduce examples of these below, and we will see more in future labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n",
    "\n",
    "The `DataSet` class is the _base_ class that can be extended for custom `DataSet` classes. Classes that extend `DataSet` must implement the following methods:\n",
    "1.  `__len__` returns the number of items available in the DataSet (e.g., the number of images)\n",
    "2.  `__getitem__` returns the item associated with the input argument (e.g., and index)\n",
    "\n",
    "For more general information on DataSet see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). For DataSet extensions specifically for image data, see [here](https://pytorch.org/vision/main/datasets.html#base-classes-for-custom-datasets) and specifically [ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # used modulo to make the dataset circular\n",
    "        # this will allow us to get batches that are larger than the dataset or repeat the dataset\n",
    "        idx = idx % len(self.x)\n",
    "        return self.x[idx], self.t[idx]\n",
    "    \n",
    "x = np.random.rand(100,3)\n",
    "t = np.random.rand(100,1)\n",
    "ds = MyDataSet(x,t)\n",
    "\n",
    "print('len(ds) = ', len(ds))\n",
    "predictors, targets = ds[0]\n",
    "print('predictors = ', predictors)\n",
    "print('targets = ', targets)\n",
    "\n",
    "# what happens if the idx is larger than the dataset\n",
    "# this works because we used modulo in the __getitem__ method\n",
    "predictors, targets = ds[x.shape[0]+10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "Typically, we can use the PyTorch `DataLoader` class without modification to load a DataSet. This is going to be useful when we train NNets using mini-batch gradient descent. The `DataLoader` is constructed with a DataSet input and a `batch_size` (which is the size of the mini-batch). The `DataLoader` can be treated as an iterator where each yielded value is a mini-batch of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy array of 0 and 1 values\n",
    "ds = MyDataSet(np.random.rand(100,3), np.random.randint(0,2,(100,1)))\n",
    "dl = DataLoader(ds, batch_size=3, shuffle=True)\n",
    "\n",
    "# print the first k batches\n",
    "k = 3\n",
    "for idx, (x,t) in enumerate(dl):\n",
    "    if idx == k:\n",
    "        break\n",
    "    print('batch ', idx)\n",
    "    print('predictors = ', x)\n",
    "    print('target = ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModules\n",
    "Typically, we will need to split our data into training, validation, and test sets. We will need a `DataLoader` for each of these. Additionally, there is often some setup work that is necessary to preprocess data samples before the data can be used for model training or inference. It will be convenient to have a single object that handles all of this functionality. This is where the PyTorch Lightning `LightningDataModule` class comes in, see [here](https://lightning.ai/docs/pytorch/stable/data/datamodule.html). It will hold the necessary DataLoader objects, prepare data as needed with in a custom `setup` method and, if needed, prepare `mini-batch` samples before sending them to the model (not shown here, we'll see this when working with text data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataModule(L.LightningDataModule):\n",
    "    def __init__(self, x, t, batch_size, val_split=0.2, test_split=0.1):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        # create a train, validation and test dataset\n",
    "\n",
    "        # first split the data into training and test\n",
    "        n = len(self.x)\n",
    "        n_val = int(n * self.val_split)\n",
    "        n_test = int(n * self.test_split)\n",
    "        n_train = n - n_val - n_test\n",
    "        \n",
    "        self.x_train = self.x[:n_train]\n",
    "        self.t_train = self.t[:n_train]\n",
    "        self.x_val = self.x[n_train:n_train+n_val]\n",
    "        self.t_val = self.t[n_train:n_train+n_val]\n",
    "        self.x_test = self.x[n_train+n_val:]\n",
    "        self.t_test = self.t[n_train+n_val:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        ds = MyDataSet(self.x_train, self.t_train)\n",
    "        return DataLoader(ds, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        ds = MyDataSet(self.x_val, self.t_val)\n",
    "        return DataLoader(ds, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        ds = MyDataSet(self.x_test, self.t_test)\n",
    "        return DataLoader(ds, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "x = np.random.rand(1000,3)\n",
    "t = np.random.rand(1000,1)\n",
    "dm = MyDataModule(x, t, batch_size=32)\n",
    "# get the train dataloader\n",
    "dl_train = dm.train_dataloader()\n",
    "\n",
    "# print the first batch from the train dataloader\n",
    "x,t = next(iter(dl_train))\n",
    "print('predictors = ', x)\n",
    "print('target = ', t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Building and Training a Model on MNIST with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data\n",
    "We are going to build a fully connected feed forward NNet to classify handwritten digits into one of ten classes, i.e., the model will indicate which number in $\\left[0,9\\right]$ is represented by hand written digit image. We will use the classic MNIST dataset. Before building the model, let's take a look at the MNIST data which is organized in a custom DataSet as part of the PyTorch torchvision library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist dataset\n",
    "# on the first run this will download the dataset\n",
    "# we need to a location to store the dataset\n",
    "# setting train=True will download the training set as well\n",
    "mnist_train_all = MNIST(dir_dataroot, train=True, download=True, transform=ToTensor())\n",
    "\n",
    "# to get the test set we can set train=False\n",
    "mnist_test = MNIST(dir_dataroot, train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# how many samples are in the training set\n",
    "print('len(mnist_train) = ', len(mnist_train_all))\n",
    "\n",
    "# how many samples are in the test set\n",
    "print('len(mnist_test) = ', len(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "batch_size = 16\n",
    "# we can create a DataLoader using the \n",
    "imgs = next(iter(DataLoader(mnist_train_all, batch_size=batch_size, shuffle=True)))[0]\n",
    "print('imgs.shape = ', imgs.shape)\n",
    "grid = make_grid(imgs, nrow=4)\n",
    "show(grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "We won't need a custom DataSet or DataModules for the MNIST data as the required functionality is provided in the MNIST class. We will need to split the training data into training and validation sets and create DataLoaders for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's seed everything for reproducibility\n",
    "seed_everything(SEED)\n",
    "batch_size = 16\n",
    "\n",
    "# split the training set into training and validation\n",
    "val_split = 0.2\n",
    "val_size = int(len(mnist_train_all) * val_split)\n",
    "train_size = len(mnist_train_all) - val_size\n",
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_all, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training samples:\",mnist_train_all.data[mnist_train.indices].shape)\n",
    "print(\"Unique classes in training:\",mnist_train_all.targets[mnist_train.indices].unique())\n",
    "\n",
    "print(\"\\nValidation samples:\", mnist_train_all.data[mnist_val.indices].shape)\n",
    "print(\"Unique classes in validation:\", mnist_train_all.targets[mnist_val.indices].unique())\n",
    "\n",
    "print(\"\\nTest samples:\", mnist_test.data.shape)\n",
    "print(mnist_test.targets.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the dataloaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the MNIST NNet Classification Model\n",
    "We are now ready to build a NNet model using PyTorch. As we consider more complex NNet architectures, it will be useful to split the models up into smaller components. This will enable us to resuse the components in other models and it will make it easier to understand the functionality of individual pieces of the model. \n",
    "\n",
    "### Modules\n",
    "We will use the `nn.Module` class to build NNet model components. Modules are used to encapsulate segments of an overal NNet model. We will see later that our NNets may be composed of multiple modules. For now, we will consider a single module representing a fully connected feed forward hidden layer. Note, this does NOT include the output layer. That will be an additional module. \n",
    "\n",
    "The `MNISTEncoder` module extends the `nn.Module` class. It includes a custom implementation of the `__init__` method and the `__forward__` method. \n",
    "\n",
    "In the `__init__` method, a `nn.Linear` object is created. This is the PyTorch implementation of a fully connected feedforward layer. It expects a 1-D input Tensor of size `input_size`. It contains `hidden_size` computation nodes. Thus the there are `input_size` X `hidden_size` weights (aka edges aka learning parameters) plus bias terms (included by default) for this layer. \n",
    "\n",
    "The `__forward__` method will take an input Tensor, `x` and __flatten__ it (meaning it will transform it from a higher order dimension to a 1-D Tensor). If `x` is $D$ dimensional with dimension sizes $\\{d_1, \\ldots, d_D\\}$ then it is required that the product of the dimensions is equal to `input_size`. For example, if `input_size` is 100 and `x` is 2-D with dimension size $d_1$ and $d_2$, then it is reaquired that $d_1 d_2 = 100$. The flattened representation of `x` is then passed through the `linear` layer which outputs the affine transformations (weighted sums) of produced by each node. Finally, those values are passed through the `ReLU` activation function. \n",
    "\n",
    "We can think of this module as __encoding__ (or __embedding__) the input image `x` into a latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "num_hidden = 64\n",
    "n_classes = 10\n",
    "input_dim = 28 \n",
    "encoder = MNISTEncoder(input_dim*input_dim, num_hidden, n_classes)\n",
    "input_image = torch.randn(1, 1, input_dim, input_dim)\n",
    "embedding = encoder(input_image)\n",
    "print('embedding.shape = ', embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to use the _encoded_ representation of the input image, `x`, from the `MNISTEncoder` module to classify the image. To do this, we will construct another module representing the output layer, which we will call `MNISTOutput`. This module will require only a `nn.Linear` module as it will process the Tensor that is output from the `MNISTEncoder.forward` method which is already 1-D. We do not use an activation function here, because in the output layer we want only the _logits_. Note that the `linear` layer accepts a Tensor of size `hidden_size` which corresponds to the number of computation units in the `linear` layer in the `MNISTEncoder`. It outputs a Tensor of size `num_classes` which for MNIST is 10. \n",
    "\n",
    "You may be wondering why we haven't included the softmax conversion of the logits in the `forward` method. It turns out, that when training the model, it will be more computationally efficient to perform this operation as part of the loss function. In the example below, we can use the `nn.functional.softmax` function to compute the probability estimates from the logits - but be careful, we haven't trained the model yet, so these are just random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTOutput(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "output = MNISTOutput(num_hidden, n_classes)\n",
    "logits = output(embedding)\n",
    "print('logits.shape = ', logits.shape)\n",
    "# These are the logits for each class\n",
    "print('logits = ', logits)\n",
    "# To get the probabilities we can use the softmax function, but remember, we haven't trained the model yet\n",
    "probs = nn.functional.softmax(logits, dim=1)\n",
    "print('probs = ', probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MNIST Classifer \n",
    "Now that we have defined the individual components of our model, we need to assemble them. Just as with our data handlers, it will prove convenient to hold our model components in a single object that also provides methods that support model training and inference. It turns out that for deep learning models, there are repeatable coding patterns that have emerged. These are abstracted in the PyTorch Lightning `LightningModule` class, see [here](https://lightning.ai/docs/pytorch/LTS/common/lightning_module.html). \n",
    "\n",
    "To build our custom `LightningModule` class, we will need to define the following methods:\n",
    "\n",
    "1. `__init__` : define any attributes or setup procedures. This will include our model component modules.\n",
    "2. `__forward__` : this will pass an input sample (or mini-batch) through our component modules\n",
    "3. `training_step` : defines what steps to perform for each training step (i.e. mini-batch). Typically, passing a mini-batch through the network and computing the loss. \n",
    "4. `validation_step` : defines what steps to perform for each validation step. Typically, passing a mini-batch through the network and computing the loss\n",
    "5. `test_step` : defines what steps to perform for each test step. Typically, passing a mini-batch through the network and computing the loss\n",
    "6. `on_validation_epoch_end` : defines what steps to perform an the end of a validation epoch (i.e., after all validation mini-batches have been evaluated by the model). This often includes a test for halting model training.\n",
    "7. `on_test_epoch_end` : defines what steps to perform an the end of a test epoch (i.e., after all test mini-batches have been evaluated by the model). This often includes storing metric values.\n",
    "8. `configure_optimizers` : define the optimization class for use in gradient descent. There are many optimizers available (we'll discuss this more in lecture). Here we use the popular Adam optimizer.\n",
    "\n",
    "The `LigtningModule` class will use the `training_step` method and the `optimizer` provided by the `configure_optimizer` method to handle updating the model parameters. We do NOT need to implement any code for that part.\n",
    "\n",
    "Note that in our implementation below, we are using the `TorchMetrics`, see [here](https://lightning.ai/docs/torchmetrics/stable/) library. the `MetricTracker` and associated metrics classes will do all the work for us in calculating and storing model performance metrics on the validation and test mini-batches. We will be able to use these to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(L.LightningModule):\n",
    "    def __init__(self, encoder, output, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.output = output\n",
    "        \n",
    "       # validation metrics - we will use these to compute the metrics at the end of the validation epoch\n",
    "        self.val_metrics_tracker = TM.wrappers.MetricTracker(TM.MetricCollection([TM.classification.MulticlassAccuracy(num_classes=num_classes)]), maximize=True)\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_step_targets = []\n",
    "\n",
    "        # test metrics - we will use these to compute the metrics at the end of the test epoch\n",
    "        self.test_roc = TM.ROC(task=\"multiclass\", num_classes=num_classes, thresholds=list(np.linspace(0.0, 1.0, 20))) # roc and cm have methods we want to call so store them in a variable\n",
    "        self.test_cm = TM.ConfusionMatrix(task='multiclass', num_classes=num_classes)\n",
    "        self.test_metrics_tracker = TM.wrappers.MetricTracker(TM.MetricCollection([TM.classification.MulticlassAccuracy(num_classes=num_classes), \n",
    "                                                            self.test_roc, self.test_cm]), maximize=True) \n",
    "        \n",
    "        # test outputs and targets - we will store the outputs and targets for the test step\n",
    "        self.test_step_outputs = []\n",
    "        self.test_step_targets = []\n",
    "\n",
    "    # the forward method applies the encoder and output to the input\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    # the training step. pass the batch through the model and compute the loss\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        # where is our softmax? We don't need it here because we are using cross_entropy which includes the softmax for efficiency\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    # the validation step. pass the batch through the model and compute the loss. Store the outputs and targets for the epoch end step and log the loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "        \n",
    "        # store the outputs and targets for the epoch end step\n",
    "        self.validation_step_outputs.append(logits)\n",
    "        self.validation_step_targets.append(y)\n",
    "        return loss\n",
    "    \n",
    "    # the test step. pass the batch through the model and compute the loss. Store the outputs and targets for the epoch end step and log the loss\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.test_step_outputs.append(logits)\n",
    "        self.test_step_targets.append(y)\n",
    "        return loss\n",
    "    \n",
    "    # at the end of the epoch compute the metrics\n",
    "    def on_validation_epoch_end(self):\n",
    "        # stack all the outputs and targets into a single tensor\n",
    "        all_preds = torch.vstack(self.validation_step_outputs)\n",
    "        all_targets = torch.hstack(self.validation_step_targets)\n",
    "        \n",
    "        # compute the metrics\n",
    "        loss = nn.functional.cross_entropy(all_preds, all_targets)\n",
    "        self.val_metrics_tracker.increment()\n",
    "        self.val_metrics_tracker.update(all_preds, all_targets)\n",
    "        self.log('val_loss_epoch_end', loss)\n",
    "        \n",
    "        # clear the validation step outputs\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_step_targets.clear()\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        all_preds = torch.vstack(self.test_step_outputs)\n",
    "        all_targets = torch.hstack(self.test_step_targets)\n",
    "        \n",
    "        self.test_metrics_tracker.increment()\n",
    "        self.test_metrics_tracker.update(all_preds, all_targets)\n",
    "        # clear the test step outputs\n",
    "        self.test_step_outputs.clear()\n",
    "        self.test_step_targets.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the MNIST model\n",
    "Now that we have constructed our model Class, we just need to instantiate an instance of this class and train it. Fortunately, because we are using a LightningModule to represent our model, we can use the PyTorch Lightning `Trainer` class to execute model training. It will do everything for us! All we need to do is instantiate an instance of the `Trainer` class with our model and call the `fit` method. \n",
    "\n",
    "Here, we have also included a __callback__ argument in the `Trainer`. Specificall, we've added the `EarlyStopping` callback which we've told to monitor the `val_loss_epoch_end` value. This callback will check this value every training epoch to determine if model training should be halted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "encoder = MNISTEncoder(input_dim*input_dim, num_hidden, n_classes)\n",
    "output = MNISTOutput(num_hidden, n_classes)\n",
    "model = MNISTClassifier(encoder, output, num_classes=n_classes)\n",
    "\n",
    "max_epochs = 1 # we're using a small number here for demonstration. Try a larger number like 10 for better performance.\n",
    "trainer = L.Trainer(default_root_dir=dir_lightning, \n",
    "                    max_epochs=max_epochs,\n",
    "                    callbacks=[EarlyStopping(monitor=\"val_loss_epoch_end\", mode=\"min\")])\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Accuracy\n",
    "Now we can use the metrics trackers from our model to examine performance. First let's look at the validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = model.val_metrics_tracker.compute_all()['MulticlassAccuracy']\n",
    "plt.plot(range(1, len(mca)+1), mca, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Epoch Validation Accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Performance\n",
    "We can also evaluate the model on the test set. First, we use the trainer to execute the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get the performance metric results from the test metrics tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = model.test_metrics_tracker.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the test set results. First we'll examine the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = sns.heatmap(rslt['MulticlassConfusionMatrix'], annot=True, fmt='d', cmap='Blues')\n",
    "cmp.set_xlabel('Predicted Label')\n",
    "cmp.set_xticklabels(mnist_train_all.classes, rotation=90)\n",
    "cmp.set_yticklabels(mnist_train_all.classes, rotation=0)\n",
    "cmp.set_ylabel('Actual Label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the intra-calss ROC results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = rslt['MulticlassROC']\n",
    "for i in range(10):\n",
    "    plt.plot(fpr[i], tpr[i], label=mnist_train_all.classes[i])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ultimately want to generate predictions from the model without using the `Trainer` object. Below, we do this to on the test data to generate a classification report using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")   #\"cuda:0\"\n",
    "# put the model in evaluation mode so that the parameters are fixed and we don't compute gradients\n",
    "model.eval()\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "# use torch.no_grad() to disable gradient computation\n",
    "with torch.no_grad():\n",
    "    # iterate over the test loader minibatches\n",
    "    for test_data in test_loader:\n",
    "        # get the images and labels from the test loader and move them to the cpu. this will make it easier to use them with sklearn\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=mnist_train_all.classes,digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc4300torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
