{"cells":[{"cell_type":"markdown","metadata":{"id":"N2pWBXj23LZ6"},"source":["<div class='heading'>\n","    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n","     <img style=\"float: right; padding-right: 10px\" width=\"100\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>\n","     </div>\n","\n","**Clemson University**<br>\n","**Fall 2024**<br>\n","**Instructor(s):** Aaron Masino <br>\n","\n","## Homework 8: Frequent Itemsets and Association Rules\n","This homework is intended to assess your knowledge of frequent itemset and association rule concepts and methods for their discovery using the Python MLXtend library. You may reference:\n","-  Python documentation [here](https://www.python.org/)\n","-  MLXtend documentation [here](https://rasbt.github.io/mlxtend/)"]},{"cell_type":"markdown","metadata":{"id":"uTTbQs-c3LZ8"},"source":["# Setup Instructions\n","In the exercises below, you will use data from the following files. Make sure you have copied these to the appropriate location (e.g., _YOUR_COURSE_DIR/data_):\n","- actorfilms.csv\n","\n","### Before beginning the exercises:\n","Execute the first two code cells to import the required Python packages mount the Google Drive.\n","\n","To begin, first import the Python packages that are required for this homework:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKHlwa_13LZ8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import preprocessing\n","from mlxtend.frequent_patterns import apriori, association_rules\n","from mlxtend.preprocessing import TransactionEncoder\n","from pandas.plotting import parallel_coordinates\n","import os"]},{"cell_type":"code","source":["# mount the google drive - this is necessary to access supporting resources\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"riS0bZft3lQo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ooP54xA3LZ9"},"source":["# Exercise 1 (2 points)\n","In the code cell below, implement the `support_for_unique_items` function. The function input, `records`, is list of transactions. Each transaction is a list of the items in the transaction. For example, the records input could be:\n","\n","```[['a','b'], ['b','c','d'], ['a'], ['b','a', 'd']]```\n","\n","Your implementation should return a dictionary where the keys are the the unique items and the values are the support for the item. For the example above, the result would be:\n","\n","```{'a':3, 'b':3, 'c':1, 'd':2}```\n","\n","Your solution does __NOT__ need to scale the support (i.e., by dividing by the number of records)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fciblJux3LZ9"},"outputs":[],"source":["def support_for_unique_items(records):\n","    ########### YOUR CODE HERE ###########"]},{"cell_type":"markdown","metadata":{"id":"wPlMKrl53LZ9"},"source":["# Excercise 2 (2 points)\n","In the code cell below implement the `support_for_itemset` function. The function inputs include:\n","- `records` : list of transactions. Each transaction is a list of the items in the transaction.\n","- `itemset' : a list representing an itemset\n","\n","For example, given the records:\n","\n","```[['a','b'], ['b','c','d'], ['a'], ['b','a', 'd']]```\n","\n","and `itemset=['a','b']` the support is 2 (the first and last record contain 'a' and 'b'). HINT: The `set`  method and `issubset` methods may be used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9iE-ZYr-3LZ9"},"outputs":[],"source":["def support_for_itemset(records, itemset):\n","    ########### YOUR CODE HERE ###########"]},{"cell_type":"markdown","metadata":{"id":"WRTHNvWe3LZ-"},"source":["# Exercise 3 (2 points)\n","In the code cell below, a set of records is generated with the `random_itemset` function. Use your implementation of `support_for_unique_items` function to obtain the support (i.e., the counts) for each unique item in `records`. Divide the resulting support values by the number of records, `num_records`, to create a scaled value representing the fraction of records in which each unique item appers. Finally, plot the number of unique items that would be considered frequent as a function of the threshold values in `thresholds`. Recall, an item is considered frequent if it's scaled support is greater than or equal to the threshold."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4q1Rfcyb3LZ-"},"outputs":[],"source":["########### DO NOT MODIFY THIS CODE ###########\n","def random_itemset(items, prob):\n","    record = [item for item in items if np.random.rand() < prob]\n","    # if record is empty, randomly select one item\n","    if len(record) == 0:\n","        record.append(items[np.random.choice(range(len(items)))])\n","    return record\n","\n","num_records = 100\n","p = 0.2 # probability of an item being in a record\n","records = [random_itemset(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'], p) for _ in range(num_records)]\n","thresholds = np.linspace(0, 1, 10)\n","\n","########### YOUR CODE HERE ###########\n","support = None"]},{"cell_type":"markdown","metadata":{"id":"za5abhNT3LZ_"},"source":["# Exercise 4 (1 points)\n","In the code cell below, database of movie \"transactions\" has been created. Each \"transaction\" corresponds to a single movie and the items in the \"transaction\" are the actors that starred in the movie. Additionally, the `MLXtend` library's `TransactionEncoder` has been applied to create the `onehot` variable which is a Pandas DataFrame where each row is a record (i.e., a movie) and each column is an actor name. The column values indicate if the actor starred in the movie. Use the `apriori` function from the `MLXtend` library to identify the frequent itemsets using the following input values:\n","- min_support = 0.0005\n","- use_colnames = True\n","- max_len = 3\n","\n","Finally, display the 10 frequent itemsets with the highest support."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDcvb62y3LZ_"},"outputs":[],"source":["########### DO NOT MODIFY THIS CODE ###########\n","max_year = 1960\n","min_films = 5\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/cpsc-4300-6300/data/actorfilms.csv\")\n","df = df[df['Year']<=max_year]\n","\n","# filter rows for actors who have acted in less than 3 films\n","df = df.groupby('Actor').filter(lambda x: len(x) >= min_films).reset_index(drop=True)\n","df.head(20)\n","\n","df = df[['Actor', 'Film']].groupby('Film').agg(lambda x: list(x))\n","records = df['Actor'].values.tolist()\n","te = TransactionEncoder()\n","onehot = te.fit_transform(records)\n","onehot = pd.DataFrame(onehot, columns = te.columns_)\n","print(f'The dataset has {onehot.shape[0]} records and {onehot.shape[1]} columns')\n","print('Each row represents a film and each column an actor')\n","print(f'All films were released before {max_year} and all actors have acted in at least {min_films} films')\n","\n","########### YOUR CODE HERE ###########\n","frequent_itemsets=None\n"]},{"cell_type":"markdown","metadata":{"id":"WNs0g-pt3LZ_"},"source":["# Exercise 5 (1 point)\n","In the code cell below, use the `association_rules` method from the `MLXtend` library to identify the association rules found when using the `frequent_itemsets` from the movie dataset in the previous exercise. Display the 5 rules with the highest `consequent support`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmfyw58E3LZ_"},"outputs":[],"source":["########### YOUR CODE HERE ###########\n","rules=None"]},{"cell_type":"markdown","metadata":{"id":"3FVFvxoH3LZ_"},"source":["# Excercise 6 (1 point)\n","In the code cell below, create a `parallel_coordinates` plot of the `support`, `confidence`, and `lift` of the `rules` that were obtained in the previous exercise."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkVPNUxZ3LZ_"},"outputs":[],"source":["########### YOUR CODE HERE ###########"]},{"cell_type":"markdown","metadata":{"id":"VWkch3F53LZ_"},"source":["# Exercise 7 (1 point)\n","In the code cell below, print the rules from exercise 5 with `confidence>=0.99` and `lift>200` and sort them by `consequent support` in _ascending_ order."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xSxKTjj3LZ_"},"outputs":[],"source":["########### YOUR CODE HERE ###########"]}],"metadata":{"kernelspec":{"display_name":"cpsc4300","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}