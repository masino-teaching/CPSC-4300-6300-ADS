{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "     <img style=\"float: right; padding-right: 10px\" width=\"100\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>\n",
    "     </div>\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Fall 2024**<br>\n",
    "**Instructor(s):** Aaron Masino <br>\n",
    "\n",
    "## Homework 6: Introduction to Neural Networks, PyTorch & PyTorch Lightning\n",
    "This homework is intended to assess your knowledge of feed forward artificial neural networks and implementation using PyTorch and PyTorch Lightning. As presented in class, these Python libraries provide support for neural network, including deep-learning, model development and analysis. For complete information, you may reference:\n",
    "-  Python documentation [here](https://www.python.org/)\n",
    "-  PyTorch documentation [here](https://pytorch.org/)\n",
    "-  PyTorch Lightning documentation[here](https://lightning.ai/docs/pytorch/stable/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Instructions\n",
    "Execute the first two code cells to import the required Python packages create the necessary data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F \n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import torchmetrics as TM\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "def create_data_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "dir_dataroot = os.path.join(\"..\", \"data\")\n",
    "create_data_directory(dir_dataroot)\n",
    "\n",
    "dir_lightning = os.path.join(\"..\", \"lightning\")\n",
    "create_data_directory(dir_lightning)\n",
    "\n",
    "SEED = 123456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1 (2 points)\n",
    "In the code cell below, assign to the variable `t` a two dimensional (2-D) PyTorch Tensor with 5 rows (first dimension) and 3 columns (second dimension) of random numbers selected from a uniform distribution on $\\left[100,110\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### START YOUR CODE HERE #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2 (1 point)\n",
    "In the code cell below, use Tensor slicing to select and print the first two rows of the PyTorch Tensor `t`. Print ONLY the first two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "t = torch.rand(3,10)\n",
    "\n",
    "########### START YOUR CODE HERE #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (1 point)\n",
    "In the code cell below, create a PyTorch Tensor, `t_dp` containg the dot product of each row (first dimension) of the tensors `t1` and `t2`. Hint: It is acceptable to use a `for` loop in your solution, however, a more computationally efficient solution will use the [torch.sum](https://pytorch.org/docs/stable/generated/torch.sum.html) method. Your final results should be a 1-D Tensor with 25 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(25,5)\n",
    "t2 = torch.rand(25,5)\n",
    "\n",
    "############ START YOUR CODE HERE #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1 point)\n",
    "In the code cell below, complete the function `can_be_matmul` which should return `True` if the input tensors `t_left` and `t_right` can be multiplied (in the matrix multiplication sens) and `False` otherwise. Your solution should first check if each Tensor is exactly two-dimensional and if the dimensions are appropriate for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_be_matmul(t_left, t_right):\n",
    "    ############ START YOUR CODE HERE #############\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remaining exercises, you will be working with the __Fashion MNIST__ dataset. Fashion-MNIST is a dataset consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes related to the type of clothing article shown in the image. For more information on this dataset, see [https://github.com/zalandoresearch/fashion-mnist](Fashion MNIST github).\n",
    "\n",
    "Execute the code in the following cell to load the train and test data from the the Fashion MNIST dataset. You should not modify this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "fashion_train_all = FashionMNIST(root=dir_dataroot, download=True, train=True, transform=ToTensor())\n",
    "fashion_test = FashionMNIST(root=dir_dataroot, download=True, train=False, transform=ToTensor())\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "show(make_grid(next(iter(DataLoader(fashion_train_all, batch_size=16, shuffle=True)))[0], nrow=4))\n",
    "\n",
    "seed_everything(SEED)\n",
    "batch_size = 16\n",
    "\n",
    "val_split = 0.2\n",
    "val_size = int(len(fashion_train_all) * val_split)\n",
    "train_size = len(fashion_train_all) - val_size\n",
    "fashion_train, fashion_val = torch.utils.data.random_split(fashion_train_all, [train_size, val_size])\n",
    "\n",
    "print(\"Training samples:\",fashion_train_all.data[fashion_train.indices].shape)\n",
    "print(\"Unique classes in training:\",fashion_train_all.targets[fashion_train.indices].unique())\n",
    "\n",
    "print(\"\\nValidation samples:\", fashion_train_all.data[fashion_val.indices].shape)\n",
    "print(\"Unique classes in validation:\", fashion_train_all.targets[fashion_val.indices].unique())\n",
    "\n",
    "print(\"\\nTest samples:\",fashion_test.data.shape)\n",
    "print(fashion_test.targets.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (1 point)\n",
    "In the code cell below, use the PyTorch `DataLoader` class to construct three data loaders, one each for the `fashion_train`, `fashion_val` and the `fashion_test` datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ START YOUR CODE HERE #############\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 6 (1 point)\n",
    "In the code cell below, complete the `make_encoder` function. This function will instantiate an instance of the `FashionEncoder` class based on the inputs:\n",
    "- `sample_image` : a single image that is a two dimensional (2-D) tensor\n",
    "- `hidden_size` : the desired number of hidden units\n",
    "- `num_classes` : the number of classes in the dataset\n",
    "\n",
    "Your solution for the `make_encoder` function should use the `sample_image` size to determine the value of the `input_dim` needed to create the `FashionEncoder` instance and assign it to teh `encoder` variable which is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "class FashionEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def make_encoder(sample_image, num_hidden, num_classes):\n",
    "    encoder = None\n",
    "    ############ START YOUR CODE HERE #############\n",
    "    \n",
    "    \n",
    "    ############ END YOUR CODE HERE #############\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 (2 points)\n",
    "In the code cell below, the variable `model` is an instance of the `UntrainedModel` class. This is a fully conected feed forward neural network that has not been trained on any data (it's weights are randomly initialized). Use the model to predict the class label for the set of sample images in the `images` variable. Print the predicted class labels. Print the true labels which are contained in the variable, `labels`. You should expect the model predictions are wrong for most of the samples because it has not been trained (it might get lucky on some)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "class FashionOutput(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "class UntrainedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = FashionEncoder(28*28, 16, 10) \n",
    "        self.output = FashionOutput(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "model = UntrainedModel()\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "############ START YOUR CODE HERE #############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 (1 point)\n",
    "In the code cell below, the class `FashionClassifier` has already been implemented. In the next code cell, an instance of the classifer has been created. For this exercise, create an instance of the PyTorch Lightning `Trainer` class. Use the trainer to train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT MODIFY THIS CODE #############\n",
    "class FashionClassifier(L.LightningModule):\n",
    "    def __init__(self, encoder, output, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.output = output\n",
    "        \n",
    "       # validation metrics - we will use these to compute the metrics at the end of the validation epoch\n",
    "        self.val_metrics_tracker = TM.wrappers.MetricTracker(TM.MetricCollection([TM.classification.MulticlassAccuracy(num_classes=num_classes)]), maximize=True)\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_step_targets = []\n",
    "\n",
    "        # test metrics - we will use these to compute the metrics at the end of the test epoch\n",
    "        self.test_roc = TM.ROC(task=\"multiclass\", num_classes=num_classes) # roc and cm have methods we want to call so store them in a variable\n",
    "        self.test_cm = TM.ConfusionMatrix(task='multiclass', num_classes=num_classes)\n",
    "        self.test_metrics_tracker = TM.wrappers.MetricTracker(TM.MetricCollection([TM.classification.MulticlassAccuracy(num_classes=num_classes), \n",
    "                                                            self.test_roc, self.test_cm]), maximize=True) \n",
    "        \n",
    "        # test outputs and targets - we will store the outputs and targets for the test step\n",
    "        self.test_step_outputs = []\n",
    "        self.test_step_targets = []\n",
    "\n",
    "    # the forward method applies the encoder and output to the input\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    # the training step. pass the batch through the model and compute the loss\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        # where is our softmax? We don't need it here because we are using cross_entropy which includes the softmax for efficiency\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    # the validation step. pass the batch through the model and compute the loss. Store the outputs and targets for the epoch end step and log the loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "        \n",
    "        # store the outputs and targets for the epoch end step\n",
    "        self.validation_step_outputs.append(logits)\n",
    "        self.validation_step_targets.append(y)\n",
    "        return loss\n",
    "    \n",
    "    # the test step. pass the batch through the model and compute the loss. Store the outputs and targets for the epoch end step and log the loss\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.test_step_outputs.append(logits)\n",
    "        self.test_step_targets.append(y)\n",
    "        return loss\n",
    "    \n",
    "    # at the end of the epoch compute the metrics\n",
    "    def on_validation_epoch_end(self):\n",
    "        # stack all the outputs and targets into a single tensor\n",
    "        all_preds = torch.vstack(self.validation_step_outputs)\n",
    "        all_targets = torch.hstack(self.validation_step_targets)\n",
    "        \n",
    "        # compute the metrics\n",
    "        loss = nn.functional.cross_entropy(all_preds, all_targets)\n",
    "        self.val_metrics_tracker.increment()\n",
    "        self.val_metrics_tracker.update(all_preds, all_targets)\n",
    "        self.log('val_loss_epoch_end', loss)\n",
    "        \n",
    "        # clear the validation step outputs\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_step_targets.clear()\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        all_preds = torch.vstack(self.test_step_outputs)\n",
    "        all_targets = torch.hstack(self.test_step_targets)\n",
    "        \n",
    "        self.test_metrics_tracker.increment()\n",
    "        self.test_metrics_tracker.update(all_preds, all_targets)\n",
    "        # clear the test step outputs\n",
    "        self.test_step_outputs.clear()\n",
    "        self.test_step_targets.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 8: Add your code to the notebook cell below to train the FashionClassifier model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "########### DO NOT MODIFY THIS CODE #############\n",
    "seed_everything(SEED)\n",
    "model = FashionClassifier(FashionEncoder(28*28, 16, 10), \n",
    "                          FashionOutput(16, 10), \n",
    "                          num_classes=10)\n",
    "\n",
    "############ START YOUR CODE HERE #############\n",
    "trainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "If you are interested, exectue the following code cells to evaluate model test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, dataloaders=test_loader)\n",
    "rslt = model.test_metrics_tracker.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = sns.heatmap(rslt['MulticlassConfusionMatrix'], annot=True, fmt='d', cmap='Blues')\n",
    "cmp.set_xlabel('Predicted Label')\n",
    "cmp.set_xticklabels(fashion_train_all.classes, rotation=90)\n",
    "cmp.set_yticklabels(fashion_train_all.classes, rotation=0)\n",
    "cmp.set_ylabel('Actual Label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = rslt['MulticlassROC']\n",
    "for i in range(10):\n",
    "    plt.plot(fpr[i], tpr[i], label=fashion_train_all.classes[i])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4300-pytorch",
   "language": "python",
   "name": "cpsc4300torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
